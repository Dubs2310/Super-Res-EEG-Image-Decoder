{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8aa7ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import torch\n",
    "sys.path.append('../../')\n",
    "from IPython.display import display\n",
    "from models.core.diffusion.pipe import Pipe\n",
    "from models.core.diffusion.custom_pipeline import Generator4Embeds\n",
    "from models.core.diffusion.diffusion_prior import DiffusionPriorUNet\n",
    "from utils.data_modules.diffusion_embedding import DiffusionEmbeddingDataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3aede8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module = DiffusionEmbeddingDataModule(\n",
    "    eeg_embeddings_file=\"/workspace/eeg-image-decoding/data/all-joined-1/eeg/embeddings/650ms-250Hz/subj01_session1_eeg_embeddings.npy\",\n",
    "    subject=1,\n",
    "    session=1,\n",
    "    batch_size=1024,\n",
    "    num_workers=4,\n",
    "    val_split=0.1,\n",
    "    test='default'\n",
    ")\n",
    "\n",
    "data_module.setup()\n",
    "train_loader = data_module.train_dataloader()\n",
    "test_loader = data_module.test_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23029ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "859de453",
   "metadata": {},
   "outputs": [],
   "source": [
    "diffusion_prior = DiffusionPriorUNet(cond_dim=1024, dropout=0.1)\n",
    "pipe = Pipe(diffusion_prior, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06ad1a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 1.2761273781458538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/venv/main/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:182: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, loss: 1.273489236831665\n",
      "epoch: 2, loss: 1.261702338854472\n",
      "epoch: 3, loss: 1.246284047762553\n",
      "epoch: 4, loss: 1.2350181341171265\n",
      "epoch: 5, loss: 1.214526891708374\n",
      "epoch: 6, loss: 1.2075467507044475\n",
      "epoch: 7, loss: 1.1927531957626343\n",
      "epoch: 8, loss: 1.1781030495961506\n",
      "epoch: 9, loss: 1.1611844698588054\n",
      "epoch: 10, loss: 1.1535508632659912\n",
      "epoch: 11, loss: 1.139157732327779\n",
      "epoch: 12, loss: 1.1270852486292522\n",
      "epoch: 13, loss: 1.1121830940246582\n",
      "epoch: 14, loss: 1.098787784576416\n",
      "epoch: 15, loss: 1.0851916472117107\n",
      "epoch: 16, loss: 1.0732665061950684\n",
      "epoch: 17, loss: 1.0606656074523926\n",
      "epoch: 18, loss: 1.0487064520517986\n",
      "epoch: 19, loss: 1.037054419517517\n",
      "epoch: 20, loss: 1.0283338228861492\n",
      "epoch: 21, loss: 1.0167561372121174\n",
      "epoch: 22, loss: 1.0056676467259724\n",
      "epoch: 23, loss: 0.9955943822860718\n",
      "epoch: 24, loss: 0.9825796484947205\n",
      "epoch: 25, loss: 0.9726263483365377\n",
      "epoch: 26, loss: 0.9590728878974915\n",
      "epoch: 27, loss: 0.9506507515907288\n",
      "epoch: 28, loss: 0.9379800955454508\n",
      "epoch: 29, loss: 0.9255949854850769\n",
      "epoch: 30, loss: 0.9149149060249329\n",
      "epoch: 31, loss: 0.9036064346631368\n",
      "epoch: 32, loss: 0.8919863899548849\n",
      "epoch: 33, loss: 0.8792734742164612\n",
      "epoch: 34, loss: 0.8674480319023132\n",
      "epoch: 35, loss: 0.8564539949099222\n",
      "epoch: 36, loss: 0.8457600474357605\n",
      "epoch: 37, loss: 0.8322382966677347\n",
      "epoch: 38, loss: 0.8209945758183798\n",
      "epoch: 39, loss: 0.8095506032307943\n",
      "epoch: 40, loss: 0.797736406326294\n",
      "epoch: 41, loss: 0.7855987350145975\n",
      "epoch: 42, loss: 0.7740110556284586\n",
      "epoch: 43, loss: 0.7625876466433207\n",
      "epoch: 44, loss: 0.7534953753153483\n",
      "epoch: 45, loss: 0.7418790459632874\n",
      "epoch: 46, loss: 0.7303309639294943\n",
      "epoch: 47, loss: 0.7197284897168478\n",
      "epoch: 48, loss: 0.7103660901387533\n",
      "epoch: 49, loss: 0.6987668673197428\n",
      "epoch: 50, loss: 0.6889125307401022\n",
      "epoch: 51, loss: 0.6801048318545023\n",
      "epoch: 52, loss: 0.6688647468884786\n",
      "epoch: 53, loss: 0.6610007484753927\n",
      "epoch: 54, loss: 0.6501833995183309\n",
      "epoch: 55, loss: 0.642585019270579\n",
      "epoch: 56, loss: 0.6319969892501831\n",
      "epoch: 57, loss: 0.6236420671145121\n",
      "epoch: 58, loss: 0.6152093609174093\n",
      "epoch: 59, loss: 0.604947030544281\n",
      "epoch: 60, loss: 0.5987723469734192\n",
      "epoch: 61, loss: 0.590823252995809\n",
      "epoch: 62, loss: 0.5821907917658488\n",
      "epoch: 63, loss: 0.5742427110671997\n",
      "epoch: 64, loss: 0.5668339133262634\n",
      "epoch: 65, loss: 0.5580348571141561\n",
      "epoch: 66, loss: 0.5514572262763977\n",
      "epoch: 67, loss: 0.5442503889401754\n",
      "epoch: 68, loss: 0.5398834149042765\n",
      "epoch: 69, loss: 0.5300668875376383\n",
      "epoch: 70, loss: 0.5252046585083008\n",
      "epoch: 71, loss: 0.516878088315328\n",
      "epoch: 72, loss: 0.509942352771759\n",
      "epoch: 73, loss: 0.5031551718711853\n",
      "epoch: 74, loss: 0.4968230923016866\n",
      "epoch: 75, loss: 0.49081099033355713\n",
      "epoch: 76, loss: 0.48434433341026306\n",
      "epoch: 77, loss: 0.47787203391393024\n",
      "epoch: 78, loss: 0.47173987825711566\n",
      "epoch: 79, loss: 0.4652651747067769\n",
      "epoch: 80, loss: 0.45895644028981525\n",
      "epoch: 81, loss: 0.45364290475845337\n",
      "epoch: 82, loss: 0.4472494622071584\n",
      "epoch: 83, loss: 0.4421268701553345\n",
      "epoch: 84, loss: 0.435836523771286\n",
      "epoch: 85, loss: 0.428874929745992\n",
      "epoch: 86, loss: 0.42371203502019245\n",
      "epoch: 87, loss: 0.4175823430220286\n",
      "epoch: 88, loss: 0.4121294319629669\n",
      "epoch: 89, loss: 0.40744952360788983\n",
      "epoch: 90, loss: 0.40125469366709393\n",
      "epoch: 91, loss: 0.39476223786671955\n",
      "epoch: 92, loss: 0.3898787200450897\n",
      "epoch: 93, loss: 0.3836684624354045\n",
      "epoch: 94, loss: 0.3791143000125885\n",
      "epoch: 95, loss: 0.37337913115819293\n",
      "epoch: 96, loss: 0.368648886680603\n",
      "epoch: 97, loss: 0.36403955022494\n",
      "epoch: 98, loss: 0.35763485232988995\n",
      "epoch: 99, loss: 0.35395950078964233\n",
      "epoch: 100, loss: 0.34811317920684814\n",
      "epoch: 101, loss: 0.3447145422299703\n",
      "epoch: 102, loss: 0.33745333552360535\n",
      "epoch: 103, loss: 0.33447925249735516\n",
      "epoch: 104, loss: 0.3279958764712016\n",
      "epoch: 105, loss: 0.32411473989486694\n",
      "epoch: 106, loss: 0.3208124240239461\n",
      "epoch: 107, loss: 0.3145739237467448\n",
      "epoch: 108, loss: 0.31182021896044415\n",
      "epoch: 109, loss: 0.3065454661846161\n",
      "epoch: 110, loss: 0.30198652545611065\n",
      "epoch: 111, loss: 0.2969737748305003\n",
      "epoch: 112, loss: 0.2939666012922923\n",
      "epoch: 113, loss: 0.2889608641465505\n",
      "epoch: 114, loss: 0.28530993064244586\n",
      "epoch: 115, loss: 0.28316618005434674\n",
      "epoch: 116, loss: 0.27813105781873065\n",
      "epoch: 117, loss: 0.27427156766255695\n",
      "epoch: 118, loss: 0.2712259789307912\n",
      "epoch: 119, loss: 0.26753197113672894\n",
      "epoch: 120, loss: 0.2641655504703522\n",
      "epoch: 121, loss: 0.26094257831573486\n",
      "epoch: 122, loss: 0.25744930903116864\n",
      "epoch: 123, loss: 0.25432004531224567\n",
      "epoch: 124, loss: 0.2506478081146876\n",
      "epoch: 125, loss: 0.2475979427496592\n",
      "epoch: 126, loss: 0.24615838627020517\n",
      "epoch: 127, loss: 0.2427278459072113\n",
      "epoch: 128, loss: 0.2397445191939672\n",
      "epoch: 129, loss: 0.23814980685710907\n",
      "epoch: 130, loss: 0.23471740384896597\n",
      "epoch: 131, loss: 0.2310082366069158\n",
      "epoch: 132, loss: 0.23053186138470969\n",
      "epoch: 133, loss: 0.2287048896153768\n",
      "epoch: 134, loss: 0.2248022456963857\n",
      "epoch: 135, loss: 0.22418291866779327\n",
      "epoch: 136, loss: 0.22096391518910727\n",
      "epoch: 137, loss: 0.22038856148719788\n",
      "epoch: 138, loss: 0.21776836613814035\n",
      "epoch: 139, loss: 0.2175461252530416\n",
      "epoch: 140, loss: 0.2145788868268331\n",
      "epoch: 141, loss: 0.21231176455815634\n",
      "epoch: 142, loss: 0.21053285896778107\n",
      "epoch: 143, loss: 0.20834455887476602\n",
      "epoch: 144, loss: 0.20771465202172598\n",
      "epoch: 145, loss: 0.20695336163043976\n",
      "epoch: 146, loss: 0.2041153460741043\n",
      "epoch: 147, loss: 0.20132225255171457\n",
      "epoch: 148, loss: 0.2010133663813273\n",
      "epoch: 149, loss: 0.19983388980229697\n"
     ]
    }
   ],
   "source": [
    "model_name = 'diffusion_prior' # 'diffusion_prior_vice_pre_imagenet' or 'diffusion_prior_vice_pre'\n",
    "pipe.train(train_loader, num_epochs=150, learning_rate=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca5b6381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diffusion prior saved to /workspace/eeg-image-decoding/code/models/check_points/diffusion_prior/subj01_session1.pt\n"
     ]
    }
   ],
   "source": [
    "save_path = f\"/workspace/eeg-image-decoding/code/models/check_points/diffusion_prior/subj01_session1.pt\"\n",
    "\n",
    "# Save the trained diffusion prior\n",
    "os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "torch.save(pipe.diffusion_prior.state_dict(), save_path)\n",
    "print(f\"Diffusion prior saved to {save_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
