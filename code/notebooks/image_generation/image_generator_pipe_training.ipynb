{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8aa7ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import torch\n",
    "sys.path.append('../../')\n",
    "from IPython.display import display\n",
    "from models.core.diffusion.pipe import Pipe\n",
    "from models.core.diffusion.custom_pipeline import Generator4Embeds\n",
    "from models.core.diffusion.diffusion_prior import DiffusionPriorUNet\n",
    "from utils.data_modules.diffusion_embedding import DiffusionEmbeddingDataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3aede8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module = DiffusionEmbeddingDataModule(\n",
    "    eeg_embeddings_file=\"/workspace/eeg-image-decoding/data/all-joined-1/eeg/embeddings/650ms-250Hz/subj01_session1_eeg_embeddings.npy\",\n",
    "    subject=1,\n",
    "    session=1,\n",
    "    batch_size=1024,\n",
    "    num_workers=4,\n",
    "    val_split=0.1,\n",
    "    test='default'\n",
    ")\n",
    "\n",
    "data_module.setup()\n",
    "train_loader = data_module.train_dataloader()\n",
    "test_loader = data_module.test_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23029ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "859de453",
   "metadata": {},
   "outputs": [],
   "source": [
    "diffusion_prior = DiffusionPriorUNet(cond_dim=1024, dropout=0.1)\n",
    "pipe = Pipe(diffusion_prior, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06ad1a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 1.2819268306096394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/venv/main/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:182: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, loss: 1.278226097424825\n",
      "epoch: 2, loss: 1.2674747308095295\n",
      "epoch: 3, loss: 1.2540096044540405\n",
      "epoch: 4, loss: 1.2388110955556233\n",
      "epoch: 5, loss: 1.2261294921239216\n",
      "epoch: 6, loss: 1.2080537875493367\n",
      "epoch: 7, loss: 1.195296287536621\n",
      "epoch: 8, loss: 1.1820848782857258\n",
      "epoch: 9, loss: 1.1660919189453125\n",
      "epoch: 10, loss: 1.1551267703374226\n",
      "epoch: 11, loss: 1.1433051824569702\n",
      "epoch: 12, loss: 1.128611445426941\n",
      "epoch: 13, loss: 1.1152995427449544\n",
      "epoch: 14, loss: 1.1026936769485474\n",
      "epoch: 15, loss: 1.0910864273707073\n",
      "epoch: 16, loss: 1.0734502871831257\n",
      "epoch: 17, loss: 1.0607703924179077\n",
      "epoch: 18, loss: 1.0511807998021443\n",
      "epoch: 19, loss: 1.0415691137313843\n",
      "epoch: 20, loss: 1.0282485087712605\n",
      "epoch: 21, loss: 1.0178369283676147\n",
      "epoch: 22, loss: 1.0073200464248657\n",
      "epoch: 23, loss: 0.9916874567667643\n",
      "epoch: 24, loss: 0.9841941992441813\n",
      "epoch: 25, loss: 0.9749188621838888\n",
      "epoch: 26, loss: 0.9618188738822937\n",
      "epoch: 27, loss: 0.949218730131785\n",
      "epoch: 28, loss: 0.9401240348815918\n",
      "epoch: 29, loss: 0.9281348983446757\n",
      "epoch: 30, loss: 0.9175085425376892\n",
      "epoch: 31, loss: 0.9063601692517599\n",
      "epoch: 32, loss: 0.8936433990796407\n",
      "epoch: 33, loss: 0.8800094326337179\n",
      "epoch: 34, loss: 0.8704657157262167\n",
      "epoch: 35, loss: 0.8570687770843506\n",
      "epoch: 36, loss: 0.8464971979459127\n",
      "epoch: 37, loss: 0.8336340586344401\n",
      "epoch: 38, loss: 0.8218077818552653\n",
      "epoch: 39, loss: 0.8111290136973063\n",
      "epoch: 40, loss: 0.8000850081443787\n",
      "epoch: 41, loss: 0.7871583898862203\n",
      "epoch: 42, loss: 0.7751568158467611\n",
      "epoch: 43, loss: 0.7645778656005859\n",
      "epoch: 44, loss: 0.7545644640922546\n",
      "epoch: 45, loss: 0.742957870165507\n",
      "epoch: 46, loss: 0.7307283679644266\n",
      "epoch: 47, loss: 0.7200519442558289\n",
      "epoch: 48, loss: 0.7101761698722839\n",
      "epoch: 49, loss: 0.700291653474172\n",
      "epoch: 50, loss: 0.6896535754203796\n",
      "epoch: 51, loss: 0.6816549102465311\n",
      "epoch: 52, loss: 0.6711005568504333\n",
      "epoch: 53, loss: 0.6605504353841146\n",
      "epoch: 54, loss: 0.6514056324958801\n",
      "epoch: 55, loss: 0.6413440306981405\n",
      "epoch: 56, loss: 0.6333092649777731\n",
      "epoch: 57, loss: 0.624930222829183\n",
      "epoch: 58, loss: 0.617254912853241\n",
      "epoch: 59, loss: 0.6091512441635132\n",
      "epoch: 60, loss: 0.6004162430763245\n",
      "epoch: 61, loss: 0.590829054514567\n",
      "epoch: 62, loss: 0.5840080976486206\n",
      "epoch: 63, loss: 0.5753209590911865\n",
      "epoch: 64, loss: 0.5685848792394003\n",
      "epoch: 65, loss: 0.5623202125231425\n",
      "epoch: 66, loss: 0.554564893245697\n",
      "epoch: 67, loss: 0.5471378564834595\n",
      "epoch: 68, loss: 0.5396825273831686\n",
      "epoch: 69, loss: 0.5325701038042704\n",
      "epoch: 70, loss: 0.5241485635439554\n",
      "epoch: 71, loss: 0.5184034109115601\n",
      "epoch: 72, loss: 0.5125005841255188\n",
      "epoch: 73, loss: 0.5053558945655823\n",
      "epoch: 74, loss: 0.4979879359404246\n",
      "epoch: 75, loss: 0.49268869558970135\n",
      "epoch: 76, loss: 0.4855113426844279\n",
      "epoch: 77, loss: 0.4794126848379771\n",
      "epoch: 78, loss: 0.4743878444035848\n",
      "epoch: 79, loss: 0.46694167455037433\n",
      "epoch: 80, loss: 0.46134622891743976\n",
      "epoch: 81, loss: 0.45529940724372864\n",
      "epoch: 82, loss: 0.44871005415916443\n",
      "epoch: 83, loss: 0.4435298442840576\n",
      "epoch: 84, loss: 0.43706833322842914\n",
      "epoch: 85, loss: 0.4312608341375987\n",
      "epoch: 86, loss: 0.42697660128275555\n",
      "epoch: 87, loss: 0.42008645335833233\n",
      "epoch: 88, loss: 0.41341425975163776\n",
      "epoch: 89, loss: 0.4085793197154999\n",
      "epoch: 90, loss: 0.40332965056101483\n",
      "epoch: 91, loss: 0.3982421358426412\n",
      "epoch: 92, loss: 0.39179979761441547\n",
      "epoch: 93, loss: 0.3860654632250468\n",
      "epoch: 94, loss: 0.3819691240787506\n",
      "epoch: 95, loss: 0.3761813243230184\n",
      "epoch: 96, loss: 0.37076746424039203\n",
      "epoch: 97, loss: 0.3654744029045105\n",
      "epoch: 98, loss: 0.3592759072780609\n",
      "epoch: 99, loss: 0.3549876908461253\n",
      "epoch: 100, loss: 0.35084910194079083\n",
      "epoch: 101, loss: 0.344304492076238\n",
      "epoch: 102, loss: 0.34047672152519226\n",
      "epoch: 103, loss: 0.3355250954627991\n",
      "epoch: 104, loss: 0.33079443375269574\n",
      "epoch: 105, loss: 0.3255367974440257\n",
      "epoch: 106, loss: 0.3220709065596263\n",
      "epoch: 107, loss: 0.31541768709818524\n",
      "epoch: 108, loss: 0.3111911714076996\n",
      "epoch: 109, loss: 0.30976752440134686\n",
      "epoch: 110, loss: 0.3051229218641917\n",
      "epoch: 111, loss: 0.2984961271286011\n",
      "epoch: 112, loss: 0.2934696575005849\n",
      "epoch: 113, loss: 0.2896068294843038\n",
      "epoch: 114, loss: 0.2860596974690755\n",
      "epoch: 115, loss: 0.2830163737138112\n",
      "epoch: 116, loss: 0.27988530198733014\n",
      "epoch: 117, loss: 0.2754921813805898\n",
      "epoch: 118, loss: 0.2719405194123586\n",
      "epoch: 119, loss: 0.2698662579059601\n",
      "epoch: 120, loss: 0.2642216781775157\n",
      "epoch: 121, loss: 0.26075931390126544\n",
      "epoch: 122, loss: 0.25968997677167255\n",
      "epoch: 123, loss: 0.25574251015981037\n",
      "epoch: 124, loss: 0.2542754113674164\n",
      "epoch: 125, loss: 0.2510128766298294\n",
      "epoch: 126, loss: 0.24633352955182394\n",
      "epoch: 127, loss: 0.24325062334537506\n",
      "epoch: 128, loss: 0.24237877130508423\n",
      "epoch: 129, loss: 0.240807314713796\n",
      "epoch: 130, loss: 0.23519568145275116\n",
      "epoch: 131, loss: 0.23306549588839212\n",
      "epoch: 132, loss: 0.23111300667126974\n",
      "epoch: 133, loss: 0.23148433367411295\n",
      "epoch: 134, loss: 0.22801489134629568\n",
      "epoch: 135, loss: 0.2242539922396342\n",
      "epoch: 136, loss: 0.22301911314328512\n",
      "epoch: 137, loss: 0.22107744216918945\n",
      "epoch: 138, loss: 0.21901607513427734\n",
      "epoch: 139, loss: 0.21657918393611908\n",
      "epoch: 140, loss: 0.21395657459894815\n",
      "epoch: 141, loss: 0.21354891856511435\n",
      "epoch: 142, loss: 0.21154849231243134\n",
      "epoch: 143, loss: 0.20955607295036316\n",
      "epoch: 144, loss: 0.20852643748124441\n",
      "epoch: 145, loss: 0.20712929964065552\n",
      "epoch: 146, loss: 0.20626979072888693\n",
      "epoch: 147, loss: 0.20306108395258585\n",
      "epoch: 148, loss: 0.20225026706854501\n",
      "epoch: 149, loss: 0.20040405293305716\n"
     ]
    }
   ],
   "source": [
    "model_name = 'diffusion_prior' # 'diffusion_prior_vice_pre_imagenet' or 'diffusion_prior_vice_pre'\n",
    "pipe.train(train_loader, num_epochs=150, learning_rate=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca5b6381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diffusion prior saved to ../models/check_points/diffusion_prior/subj01_session1.pt\n"
     ]
    }
   ],
   "source": [
    "save_path = f\"/workspace/eeg-image-decoding/code/models/check_points/diffusion_prior/subj01_session1.pt\"\n",
    "\n",
    "# Save the trained diffusion prior\n",
    "os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "torch.save(pipe.diffusion_prior.state_dict(), save_path)\n",
    "print(f\"Diffusion prior saved to {save_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
