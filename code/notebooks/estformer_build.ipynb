{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "faee4684",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.api.layers import Input, Dense, Flatten, MultiHeadAttention, Concatenate, Add, Permute, Dropout, LayerNormalization, Reshape, Layer\n",
    "from keras.api.models import Model, Sequential\n",
    "from keras.api.optimizers import Adam\n",
    "from keras.api.losses import MeanSquaredError\n",
    "from keras.api.metrics import MeanAbsoluteError\n",
    "from keras.api.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from mne.channels import make_standard_montage, get_builtin_montages\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a29e0353",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAB(Layer):\n",
    "    # TODO: embed dim for temporal is the number of channels\n",
    "    # TODO: embed dim for spatial is the number of encoded channels feature map, i.e. d_model\n",
    "    def __init__(self, embed_dim, num_heads, mlp_dim, spatial_or_temporal=\"spatial\", dropout_rate=0.1):\n",
    "        super(SAB, self).__init__()\n",
    "\n",
    "        if spatial_or_temporal not in [\"spatial\", \"temporal\"]:\n",
    "            raise ValueError(\"spatial_or_temporal must be either 'spatial' or 'temporal'\")\n",
    "        \n",
    "        self.spatial_or_temporal = spatial_or_temporal\n",
    "        \n",
    "        self.norm1 = LayerNormalization(epsilon=1e-6)\n",
    "        self.attn = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim, dropout=dropout_rate)\n",
    "        self.dropout1 = Dropout(dropout_rate)\n",
    "        self.norm2 = LayerNormalization(epsilon=1e-6)\n",
    "        self.mlp = Sequential([\n",
    "            Dense(mlp_dim, activation='gelu'),  # (None, 60, 128)\n",
    "            Dropout(dropout_rate),\n",
    "            Dense(embed_dim),                   # (None, 60, 14)\n",
    "            Dropout(dropout_rate)               \n",
    "        ])\n",
    "\n",
    "    def call(self, inp, L=1, training=False):\n",
    "        # x shape: (batch_size, channels, time_steps)\n",
    "        # (None, 14, 60)\n",
    "        out = inp\n",
    "        is_temporal = self.spatial_or_temporal == \"temporal\"\n",
    "\n",
    "        if is_temporal:\n",
    "            out = Permute((2, 1))(out) # Change to (batch_size, time_steps, channels) (None, 60, 14)\n",
    "            \n",
    "        for _ in range(L):\n",
    "            out_norm = self.norm1(out)\n",
    "            attn_output = self.attn(out_norm, out_norm)\n",
    "            out1 = out + self.dropout1(attn_output, training=training)\n",
    "\n",
    "            out1_norm = self.norm2(out1) # (None, 60, 14)\n",
    "            mlp_output = self.mlp(out1_norm, training=training)\n",
    "            out2 = out1 + mlp_output\n",
    "\n",
    "            out += out2\n",
    "            \n",
    "        if is_temporal:\n",
    "            out = Permute((2, 1))(out) # Change back to (batch_size, channels, time_steps)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5ec01813",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CAB(Layer):\n",
    "    def __init__(self, embed_dim, d_model, num_heads, mlp_dim, dropout_rate=0.1):\n",
    "        super(CAB, self).__init__()\n",
    "        self.tsab1 = SAB(embed_dim, num_heads, mlp_dim, spatial_or_temporal=\"temporal\", dropout_rate=dropout_rate)\n",
    "        self.ssab = SAB(d_model, num_heads, mlp_dim, spatial_or_temporal=\"spatial\", dropout_rate=dropout_rate)\n",
    "        self.tsab2 = SAB(embed_dim, num_heads, mlp_dim, spatial_or_temporal=\"temporal\", dropout_rate=dropout_rate)\n",
    "\n",
    "    def call(self, inp, L=1, training=False):\n",
    "        # inp shape: (batch_size, channels, time_steps)\n",
    "        # (None, 14, 60)\n",
    "        out = inp\n",
    "        for _ in range(L):\n",
    "            print(\"[CAB]\\n\")\n",
    "\n",
    "            out1 = self.tsab1(out, training=training)\n",
    "            out1 = out + out1\n",
    "            print(\"TSAB1\")\n",
    "\n",
    "            out2 = self.ssab(out1, training=training)\n",
    "            out2 = out1 + out2\n",
    "            print(\"SSAB\")\n",
    "\n",
    "            out3 = self.tsab2(out2, training=training)\n",
    "            out3 = out2 + out3\n",
    "            out += out3\n",
    "            print(\"TSAB2\\n\")\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "afc4c887",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_3d_positional_encoding(channel_names, d_model, builtin_montage=None, positions=[]):\n",
    "    num_channels = len(channel_names)\n",
    "    builtin_montages = get_builtin_montages()\n",
    "\n",
    "    if num_channels == 0:\n",
    "        raise ValueError(\"The number of channels must be greater than 0.\")\n",
    "    \n",
    "    if builtin_montage and positions:\n",
    "        raise ValueError(\"You can only use either builtin_montage or positions, not both.\")\n",
    "    \n",
    "    if not builtin_montage and positions and len(positions) != num_channels:\n",
    "        raise ValueError(\"The number of positions must match the number of channels.\")\n",
    "    \n",
    "    if not builtin_montage and positions and len(positions) == num_channels:\n",
    "        positions = np.array(positions)\n",
    "\n",
    "    if builtin_montage and not positions and builtin_montage not in builtin_montages:\n",
    "        raise ValueError(f\"Montage '{builtin_montage}' is not available. Please choose from {builtin_montages}.\")\n",
    "    \n",
    "    if builtin_montage and not positions and builtin_montage in builtin_montages:\n",
    "        builtin_montage = make_standard_montage(builtin_montage)\n",
    "        pos_dict = builtin_montage.get_positions()['ch_pos']\n",
    "        positions = np.array([pos_dict[ch] for ch in channel_names])  # shape: (num_channels, 3)\n",
    "\n",
    "    assert d_model % 3 == 0, \"d_model must be divisible by 3.\"\n",
    "    d_model_per_axis = d_model // 3\n",
    "    print(type(d_model_per_axis))\n",
    "\n",
    "    pos_encoding = []\n",
    "\n",
    "    for axis in range(3):\n",
    "        pos = positions[:, axis]\n",
    "        pe = np.zeros((num_channels, d_model_per_axis))\n",
    "        for i in range(d_model_per_axis):\n",
    "            div_term = np.power(10000.0, (2 * i) / d_model_per_axis)\n",
    "            pe[:, i] = np.where(i % 2 == 0, np.sin(pos / div_term), np.cos(pos / div_term))\n",
    "    \n",
    "        pos_encoding.append(pe)\n",
    "\n",
    "    pos_encoding = np.concatenate(pos_encoding, axis=-1)    # shape: (num_channels, d_model)\n",
    "    pos_encoding = np.expand_dims(pos_encoding, axis=0)     # shape: (1, num_channels, d_model)\n",
    "    return tf.constant(pos_encoding, dtype=tf.float32)      # shape: (1, num_channels, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "11f889a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SIM(Layer):\n",
    "    def __init__(self, embed_dim, d_model, num_heads, mlp_dim, low_res_ch_names, high_res_ch_names, dropout_rate=0.1, builtin_montage=None, positions=[]):\n",
    "        super(SIM, self).__init__()\n",
    "        self.cab = CAB(embed_dim, d_model, num_heads, mlp_dim, dropout_rate=dropout_rate)\n",
    "        self.norm = LayerNormalization(epsilon=1e-6)\n",
    "        self.dense = Dense(d_model, activation='gelu')\n",
    "        self.low_res_3d_pos_encoding = generate_3d_positional_encoding(low_res_ch_names, d_model, builtin_montage=builtin_montage, positions=positions)\n",
    "        self.high_res_3d_pos_encoding = generate_3d_positional_encoding(high_res_ch_names, d_model, builtin_montage=builtin_montage, positions=positions)\n",
    "        self.mask_token = tf.Variable(initial_value=tf.zeros([1, d_model]), trainable=True)\n",
    "        \n",
    "    def call(self, inp, L=1, training=False):\n",
    "        # inp shape: (batch_size, channels, time_steps)\n",
    "        # (None, 14, 57)\n",
    "        print(\"[SIM]\\n\")\n",
    "        out = inp                                       # channel embedding\n",
    "        out = self.dense(out)                           # (None, 14, 60)\n",
    "        out = out + self.low_res_3d_pos_encoding        # (None, 14, 60)\n",
    "        print(\"CAB1\")\n",
    "        out = self.cab(out, L=L, training=training)\n",
    "        out = self.norm(out)                            # feature projection\n",
    "        \n",
    "        out = Concatenate([out, self.mask_token])\n",
    "        out = self.dense(out)\n",
    "        out = out + self.high_res_3d_pos_encoding\n",
    "        print(\"CAB2\\n\")\n",
    "        out = self.cab(out, L=L, training=training)\n",
    "        out = self.norm(out)\n",
    "\n",
    "        return out                                      # time projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8ec07e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_1d_positional_encoding(time_steps, d_model):\n",
    "    assert d_model % 2 == 0, \"d_model must be even for sin/cos encoding.\"\n",
    "    \n",
    "    pos_encoding = np.zeros((time_steps, d_model))  # Shape: (time_steps, d_model)\n",
    "    \n",
    "    for pos in range(time_steps):\n",
    "        for i in range(d_model // 2):\n",
    "            div_term = np.power(10000.0, (2 * i) / d_model)\n",
    "            pos_encoding[pos, 2 * i] = np.sin(pos / div_term)\n",
    "            pos_encoding[pos, 2 * i + 1] = np.cos(pos / div_term)\n",
    "\n",
    "    pos_encoding = np.expand_dims(pos_encoding, axis=0)  # Shape: (1, time_steps, d_model)\n",
    "    return tf.constant(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "77a6a18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TRM(Layer):\n",
    "    def __init__(self, embed_dim, d_model, num_heads, mlp_dim, dropout_rate=0.1):\n",
    "        super(TRM, self).__init__()\n",
    "        self.tsab = SAB(embed_dim, num_heads, mlp_dim, spatial_or_temporal=\"temporal\", dropout_rate=dropout_rate)\n",
    "        self.norm = LayerNormalization(epsilon=1e-6)\n",
    "        self.dense = Dense(d_model, activation='gelu')\n",
    "        self._1d_pos_encoding = generate_1d_positional_encoding()\n",
    "        \n",
    "    def call(self, inp, L=1, training=False):\n",
    "        # inp shape: (batch_size, channels, time_steps)\n",
    "        out = Permute((2, 1))(inp)                      # time embedding (batch_size, time_steps, channels)\n",
    "        out = self.dense(out)\n",
    "        out = out + self._1d_pos_encoding\n",
    "        out = self.tsab(out, L=L, training=training)\n",
    "        out = self.norm(out)                            # feature projection\n",
    "\n",
    "        out = self.dense(out)\n",
    "        out = out + self._1d_pos_encoding\n",
    "        out = self.tsab(out, L=L, training=training)\n",
    "        out = self.norm(out)                            # feature projection\n",
    "        out = Permute((2, 1))(out)                      # reshape to (batch_size, channels, time_steps)\n",
    "        return out                                      # channel projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "96e935c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIM\n",
      "<class 'int'>\n",
      "<class 'int'>\n",
      "[SIM]\n",
      "\n",
      "CAB1\n",
      "[CAB]\n",
      "\n",
      "TSAB1\n",
      "SSAB\n",
      "TSAB2\n",
      "\n",
      "[CAB]\n",
      "\n",
      "TSAB1\n",
      "SSAB\n",
      "TSAB2\n",
      "\n",
      "[SIM]\n",
      "\n",
      "CAB1\n",
      "[CAB]\n",
      "\n",
      "TSAB1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "s:\\PolySecLabProjects\\eeg-image-decode\\env\\Lib\\site-packages\\keras\\src\\layers\\layer.py:1410: UserWarning: Layer 'sim_18' looks like it has unbuilt state, but Keras is not able to trace the layer `call()` in order to build it automatically. Possible causes:\n",
      "1. The `call()` method of your layer may be crashing. Try to `__call__()` the layer eagerly on some test input first to see if it works. E.g. `x = np.random.random((3, 4)); y = layer(x)`\n",
      "2. If the `call()` method is correct, then you may need to implement the `def build(self, input_shape)` method on your layer. It should create all variables used by the layer (e.g. by calling `layer.build()` on all its children layers).\n",
      "Exception encountered: ''Only input tensors may be passed as positional arguments. The following argument value should be passed as a keyword argument: <Concatenate name=concatenate_4, built=False> (of type <class 'keras.src.layers.merging.concatenate.Concatenate'>)''\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSAB\n",
      "TSAB2\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling SIM.call().\n\n\u001b[1mCould not automatically infer the output shape / dtype of 'sim_18' (of type SIM). Either the `SIM.call()` method is incorrect, or you need to implement the `SIM.compute_output_spec() / compute_output_shape()` method. Error encountered:\n\nOnly input tensors may be passed as positional arguments. The following argument value should be passed as a keyword argument: <Concatenate name=concatenate_5, built=False> (of type <class 'keras.src.layers.merging.concatenate.Concatenate'>)\u001b[0m\n\nArguments received by SIM.call():\n  • args=('<KerasTensor shape=(None, 14, 57), dtype=float32, sparse=False, ragged=False, name=keras_tensor_168>',)\n  • kwargs={'L': '1', 'training': 'True'}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[50]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     11\u001b[39m input_epoch = Input(shape=(\u001b[38;5;28mlen\u001b[39m(low_res_ch_names), time_steps)) \u001b[38;5;66;03m# (batch_size, channels, time_steps)\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mSIM\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m sim = \u001b[43mSIM\u001b[49m\u001b[43m(\u001b[49m\u001b[43membed_dim\u001b[49m\u001b[43m=\u001b[49m\u001b[43membed_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43md_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_heads\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmlp_dim\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmlp_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropout_rate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdropout_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlow_res_ch_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlow_res_ch_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhigh_res_ch_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhigh_res_ch_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuiltin_montage\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbuiltin_montage\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mL\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m trm = TRM(embed_dim=embed_dim, d_model=d_model, num_heads=num_heads, mlp_dim=mlp_dim, dropout_rate=dropout_rate)(sim, L=\u001b[32m1\u001b[39m, training=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     15\u001b[39m model = sim + trm\n",
      "\u001b[36mFile \u001b[39m\u001b[32ms:\\PolySecLabProjects\\eeg-image-decode\\env\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[46]\u001b[39m\u001b[32m, line 23\u001b[39m, in \u001b[36mSIM.call\u001b[39m\u001b[34m(self, inp, L, training)\u001b[39m\n\u001b[32m     20\u001b[39m out = \u001b[38;5;28mself\u001b[39m.norm(out)                            \u001b[38;5;66;03m# feature projection\u001b[39;00m\n\u001b[32m     22\u001b[39m out = Concatenate([out, \u001b[38;5;28mself\u001b[39m.mask_token])\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m out = out + \u001b[38;5;28mself\u001b[39m.high_res_3d_pos_encoding\n\u001b[32m     25\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mCAB2\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: Exception encountered when calling SIM.call().\n\n\u001b[1mCould not automatically infer the output shape / dtype of 'sim_18' (of type SIM). Either the `SIM.call()` method is incorrect, or you need to implement the `SIM.compute_output_spec() / compute_output_shape()` method. Error encountered:\n\nOnly input tensors may be passed as positional arguments. The following argument value should be passed as a keyword argument: <Concatenate name=concatenate_5, built=False> (of type <class 'keras.src.layers.merging.concatenate.Concatenate'>)\u001b[0m\n\nArguments received by SIM.call():\n  • args=('<KerasTensor shape=(None, 14, 57), dtype=float32, sparse=False, ragged=False, name=keras_tensor_168>',)\n  • kwargs={'L': '1', 'training': 'True'}"
     ]
    }
   ],
   "source": [
    "high_res_ch_names = ['Fp1', 'Fz', 'F3', 'F7', 'FT9', 'FC5', 'FC1', 'C3', 'T7', 'TP9', 'CP5', 'CP1', 'Pz', 'P3', 'P7', 'O1', 'Oz', 'O2', 'P4', 'P8', 'TP10', 'CP6', 'CP2', 'C4', 'T8', 'FT10', 'FC6', 'FC2', 'F4', 'F8', 'Fp2', 'AF7', 'AF3', 'AFz', 'F1', 'F5', 'FT7', 'FC3', 'C1', 'C5', 'TP7', 'CP3', 'P1', 'P5', 'PO7', 'PO3', 'POz', 'PO4', 'PO8', 'P6', 'P2', 'CPz', 'CP4', 'TP8', 'C6', 'C2', 'FC4', 'FT8', 'F6', 'AF8', 'AF4', 'F2', 'FCz']\n",
    "low_res_ch_names = ['AF3', 'F7', 'F3', 'FC5', 'T7', 'P7', 'O1', 'O2', 'P8', 'T8', 'FC6', 'F4', 'F8', 'AF4']\n",
    "builtin_montage = 'standard_1020'\n",
    "time_steps = 57\n",
    "embed_dim = 14\n",
    "d_model = 60\n",
    "num_heads = 4\n",
    "mlp_dim = 128\n",
    "dropout_rate = 0.1\n",
    "\n",
    "input_epoch = Input(shape=(len(low_res_ch_names), time_steps)) # (batch_size, channels, time_steps)\n",
    "print(\"SIM\")\n",
    "sim = SIM(embed_dim=embed_dim, d_model=d_model, num_heads=num_heads, mlp_dim=mlp_dim, dropout_rate=dropout_rate, low_res_ch_names=low_res_ch_names, high_res_ch_names=high_res_ch_names, builtin_montage=builtin_montage)(input_epoch, L=1, training=True)\n",
    "trm = TRM(embed_dim=embed_dim, d_model=d_model, num_heads=num_heads, mlp_dim=mlp_dim, dropout_rate=dropout_rate)(sim, L=1, training=True)\n",
    "model = sim + trm\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b757eedf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
