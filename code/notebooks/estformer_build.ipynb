{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "faee4684",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.api.layers import Input, Dense, Flatten, MultiHeadAttention, Concatenate, Add, Permute, Dropout, LayerNormalization, Reshape, Layer\n",
    "from keras.api.models import Model, Sequential\n",
    "from keras.api.optimizers import Adam\n",
    "from keras.api.losses import MeanSquaredError\n",
    "from keras.api.metrics import MeanAbsoluteError\n",
    "from keras.api.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from mne.channels import make_standard_montage, get_builtin_montages\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a29e0353",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAB(Layer):\n",
    "    # TODO: embed dim for temporal is the number of channels\n",
    "    # TODO: embed dim for spatial is the number of encoded channels feature map, i.e. d_model\n",
    "    def __init__(self, embed_dim, num_heads, mlp_dim, spatial_or_temporal=\"spatial\", dropout_rate=0.1):\n",
    "        super(SAB, self).__init__()\n",
    "\n",
    "        if spatial_or_temporal not in [\"spatial\", \"temporal\"]:\n",
    "            raise ValueError(\"spatial_or_temporal must be either 'spatial' or 'temporal'\")\n",
    "        \n",
    "        self.spatial_or_temporal = spatial_or_temporal\n",
    "        \n",
    "        self.norm1 = LayerNormalization(epsilon=1e-6)\n",
    "        self.attn = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim, dropout=dropout_rate)\n",
    "        self.dropout1 = Dropout(dropout_rate)\n",
    "        self.norm2 = LayerNormalization(epsilon=1e-6)\n",
    "        self.mlp = Sequential([\n",
    "            Dense(mlp_dim, activation='gelu'),\n",
    "            Dropout(dropout_rate),\n",
    "            Dense(embed_dim),\n",
    "            Dropout(dropout_rate)               \n",
    "        ])\n",
    "\n",
    "    def generate(self, inp, L=1, training=False):\n",
    "        # x shape: (batch_size, channels, time_steps)\n",
    "        print(\"\\t\\tSAB called\")\n",
    "        out = inp\n",
    "        is_temporal = self.spatial_or_temporal == \"temporal\"\n",
    "\n",
    "        if is_temporal:\n",
    "            out = Permute((2, 1))(out) # Change to (batch_size, time_steps, channels)\n",
    "            \n",
    "        for _ in range(L):\n",
    "            out_norm = self.norm1(out)\n",
    "            attn_output = self.attn(out_norm, out_norm)\n",
    "            out1 = out + self.dropout1(attn_output, training=training)\n",
    "\n",
    "            out1_norm = self.norm2(out1)\n",
    "            mlp_output = self.mlp(out1_norm, training=training)\n",
    "            out2 = out1 + mlp_output\n",
    "\n",
    "            out += out2\n",
    "            \n",
    "        if is_temporal:\n",
    "            out = Permute((2, 1))(out) # Change back to (batch_size, channels, time_steps)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5ec01813",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CAB(Layer):\n",
    "    def __init__(self, embed_dim, d_model, num_heads, mlp_dim, dropout_rate=0.1):\n",
    "        super(CAB, self).__init__()\n",
    "        self.tsab1 = SAB(embed_dim, num_heads, mlp_dim, spatial_or_temporal=\"temporal\", dropout_rate=dropout_rate)\n",
    "        self.ssab = SAB(d_model, num_heads, mlp_dim, spatial_or_temporal=\"spatial\", dropout_rate=dropout_rate)\n",
    "        self.tsab2 = SAB(embed_dim, num_heads, mlp_dim, spatial_or_temporal=\"temporal\", dropout_rate=dropout_rate)\n",
    "\n",
    "    def generate(self, inp, L=1, training=False):\n",
    "        # inp shape: (batch_size, channels, time_steps)\n",
    "        out = inp\n",
    "        for _ in range(L):\n",
    "            out1 = self.tsab1.generate(out, training=training)\n",
    "            out1 = out + out1\n",
    "\n",
    "            out2 = self.ssab.generate(out1, training=training)\n",
    "            out2 = out1 + out2\n",
    "\n",
    "            out3 = self.tsab2.generate(out2, training=training)\n",
    "            out3 = out2 + out3\n",
    "            out += out3\n",
    "            print(\"[CAB] TSAB1 SSAB TSAB2\")\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "afc4c887",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_3d_positional_encoding(channel_names, d_model, builtin_montage=None, positions=[]):\n",
    "    num_channels = len(channel_names)\n",
    "    builtin_montages = get_builtin_montages()\n",
    "\n",
    "    if num_channels == 0:\n",
    "        raise ValueError(\"The number of channels must be greater than 0.\")\n",
    "    \n",
    "    if builtin_montage and positions:\n",
    "        raise ValueError(\"You can only use either builtin_montage or positions, not both.\")\n",
    "    \n",
    "    if not builtin_montage and positions and len(positions) != num_channels:\n",
    "        raise ValueError(\"The number of positions must match the number of channels.\")\n",
    "    \n",
    "    if not builtin_montage and positions and len(positions) == num_channels:\n",
    "        positions = np.array(positions)\n",
    "\n",
    "    if builtin_montage and not positions and builtin_montage not in builtin_montages:\n",
    "        raise ValueError(f\"Montage '{builtin_montage}' is not available. Please choose from {builtin_montages}.\")\n",
    "    \n",
    "    if builtin_montage and not positions and builtin_montage in builtin_montages:\n",
    "        builtin_montage = make_standard_montage(builtin_montage)\n",
    "        pos_dict = builtin_montage.get_positions()['ch_pos']\n",
    "        positions = np.array([pos_dict[ch] for ch in channel_names])  # shape: (num_channels, 3)\n",
    "\n",
    "    assert d_model % 3 == 0, \"d_model must be divisible by 3.\"\n",
    "    d_model_per_axis = d_model // 3\n",
    "\n",
    "    pos_encoding = []\n",
    "\n",
    "    for axis in range(3):\n",
    "        pos = positions[:, axis]\n",
    "        pe = np.zeros((num_channels, d_model_per_axis))\n",
    "        for i in range(d_model_per_axis):\n",
    "            div_term = np.power(10000.0, (2 * i) / d_model_per_axis)\n",
    "            pe[:, i] = np.where(i % 2 == 0, np.sin(pos / div_term), np.cos(pos / div_term))\n",
    "    \n",
    "        pos_encoding.append(pe)\n",
    "\n",
    "    pos_encoding = np.concatenate(pos_encoding, axis=-1)    # shape: (num_channels, d_model)\n",
    "    pos_encoding = np.expand_dims(pos_encoding, axis=0)     # shape: (1, num_channels, d_model)\n",
    "    return tf.constant(pos_encoding, dtype=tf.float32)      # shape: (1, num_channels, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "11f889a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SIM(Layer):\n",
    "    def __init__(self, embed_dim, d_model, num_heads, mlp_dim, low_res_ch_names, high_res_ch_names, dropout_rate=0.1, builtin_montage=None, positions=[]):\n",
    "        super(SIM, self).__init__()\n",
    "        self.dense1 = Dense(d_model, activation='gelu')\n",
    "        self.low_res_3d_pos_encoding = generate_3d_positional_encoding(low_res_ch_names, d_model, builtin_montage=builtin_montage, positions=positions)\n",
    "        self.cab1 = CAB(embed_dim, d_model, num_heads, mlp_dim, dropout_rate=dropout_rate)\n",
    "        self.norm1 = LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.mask_token = tf.Variable(initial_value=tf.zeros([1, d_model]), trainable=True)\n",
    "        \n",
    "        self.dense2 = Dense(d_model, activation='gelu')\n",
    "        self.high_res_3d_pos_encoding = generate_3d_positional_encoding(high_res_ch_names, d_model, builtin_montage=builtin_montage, positions=positions)\n",
    "        self.cab2 = CAB(embed_dim, d_model, num_heads, mlp_dim, dropout_rate=dropout_rate)\n",
    "        self.norm2 = LayerNormalization(epsilon=1e-6)\n",
    "        \n",
    "    def generate(self, inp, L=1, training=False):\n",
    "        # inp shape: (batch_size, channels, time_steps)\n",
    "        print(\"[SIM]\")\n",
    "        out = inp                                       # channel embedding\n",
    "        out = self.dense1(out)\n",
    "        out = out + self.low_res_3d_pos_encoding\n",
    "        print(\"\\tCAB1\")\n",
    "        out = self.cab1.generate(out, L=L, training=training)\n",
    "        out = self.norm1(out)                            # feature projection\n",
    "        \n",
    "        out = Concatenate([out, self.mask_token])\n",
    "        \n",
    "        out = self.dense2(out)\n",
    "        out = out + self.high_res_3d_pos_encoding\n",
    "        print(\"\\tCAB2\")\n",
    "        out = self.cab2.generate(out, L=L, training=training)\n",
    "        out = self.norm2(out)\n",
    "\n",
    "        return out                                      # time projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8ec07e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_1d_positional_encoding(time_steps, d_model):\n",
    "    assert d_model % 2 == 0, \"d_model must be even for sin/cos encoding.\"\n",
    "    \n",
    "    pos_encoding = np.zeros((time_steps, d_model))  # Shape: (time_steps, d_model)\n",
    "    \n",
    "    for pos in range(time_steps):\n",
    "        for i in range(d_model // 2):\n",
    "            div_term = np.power(10000.0, (2 * i) / d_model)\n",
    "            pos_encoding[pos, 2 * i] = np.sin(pos / div_term)\n",
    "            pos_encoding[pos, 2 * i + 1] = np.cos(pos / div_term)\n",
    "\n",
    "    pos_encoding = np.expand_dims(pos_encoding, axis=0)  # Shape: (1, time_steps, d_model)\n",
    "    return tf.constant(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "77a6a18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TRM(Layer):\n",
    "    def __init__(self, embed_dim, d_model, num_heads, mlp_dim, dropout_rate=0.1):\n",
    "        super(TRM, self).__init__()\n",
    "        self.dense1 = Dense(d_model, activation='gelu')\n",
    "        self._1d_pos_encoding = generate_1d_positional_encoding()\n",
    "        self.tsab1 = SAB(embed_dim, num_heads, mlp_dim, spatial_or_temporal=\"temporal\", dropout_rate=dropout_rate)\n",
    "        self.norm1 = LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dense2 = Dense(d_model, activation='gelu')\n",
    "        self.tsab2 = SAB(embed_dim, num_heads, mlp_dim, spatial_or_temporal=\"temporal\", dropout_rate=dropout_rate)\n",
    "        self.norm2 = LayerNormalization(epsilon=1e-6)\n",
    "        \n",
    "        \n",
    "    def call(self, inp, L=1, training=False):\n",
    "        # inp shape: (batch_size, channels, time_steps)\n",
    "        out = Permute((2, 1))(inp)                      # time embedding (batch_size, time_steps, channels)\n",
    "        out = self.dense1(out)\n",
    "        out = out + self._1d_pos_encoding\n",
    "        out = self.tsab1(out, L=L, training=training)\n",
    "        out = self.norm1(out)                            # feature projection\n",
    "\n",
    "        out = self.dense2(out)\n",
    "        out = out + self._1d_pos_encoding\n",
    "        out = self.tsab2(out, L=L, training=training)\n",
    "        out = self.norm2(out)                            # feature projection\n",
    "        out = Permute((2, 1))(out)                      # reshape to (batch_size, channels, time_steps)\n",
    "        return out                                      # channel projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "96e935c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SIM]\n",
      "\tCAB1\n",
      "\t\tSAB called\n",
      "\t\tSAB called\n",
      "\t\tSAB called\n",
      "[CAB] TSAB1 SSAB TSAB2\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Only input tensors may be passed as positional arguments. The following argument value should be passed as a keyword argument: <Concatenate name=concatenate_9, built=False> (of type <class 'keras.src.layers.merging.concatenate.Concatenate'>)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[45]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      9\u001b[39m dropout_rate = \u001b[32m0.1\u001b[39m\n\u001b[32m     11\u001b[39m input_epoch = Input(shape=(\u001b[38;5;28mlen\u001b[39m(low_res_ch_names), time_steps)) \u001b[38;5;66;03m# (batch_size, channels, time_steps)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m sim = \u001b[43mSIM\u001b[49m\u001b[43m(\u001b[49m\u001b[43membed_dim\u001b[49m\u001b[43m=\u001b[49m\u001b[43membed_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43md_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_heads\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmlp_dim\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmlp_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropout_rate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdropout_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlow_res_ch_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlow_res_ch_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhigh_res_ch_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhigh_res_ch_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuiltin_montage\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbuiltin_montage\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mL\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# trm = TRM(embed_dim=embed_dim, d_model=d_model, num_heads=num_heads, mlp_dim=mlp_dim, dropout_rate=dropout_rate)(sim, L=1, training=True)\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# model = sim + trm\u001b[39;00m\n\u001b[32m     15\u001b[39m \n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# model.summary()\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[41]\u001b[39m\u001b[32m, line 28\u001b[39m, in \u001b[36mSIM.generate\u001b[39m\u001b[34m(self, inp, L, training)\u001b[39m\n\u001b[32m     24\u001b[39m out = \u001b[38;5;28mself\u001b[39m.norm1(out)                            \u001b[38;5;66;03m# feature projection\u001b[39;00m\n\u001b[32m     26\u001b[39m out = Concatenate([out, \u001b[38;5;28mself\u001b[39m.mask_token])\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdense2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m out = out + \u001b[38;5;28mself\u001b[39m.high_res_3d_pos_encoding\n\u001b[32m     30\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[33mCAB2\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32ms:\\PolySecLabProjects\\eeg-image-decode\\env\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32ms:\\PolySecLabProjects\\eeg-image-decode\\env\\Lib\\site-packages\\keras\\src\\layers\\layer.py:814\u001b[39m, in \u001b[36mLayer.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    808\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m tree.flatten(args):\n\u001b[32m    809\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    810\u001b[39m             \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, KerasTensor)\n\u001b[32m    811\u001b[39m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m backend.is_tensor(arg)\n\u001b[32m    812\u001b[39m             \u001b[38;5;129;01mand\u001b[39;00m arg \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    813\u001b[39m         ):\n\u001b[32m--> \u001b[39m\u001b[32m814\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    815\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mOnly input tensors may be passed as \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    816\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mpositional arguments. The following argument value \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    817\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mshould be passed as a keyword argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marg\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    818\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m(of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(arg)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    819\u001b[39m             )\n\u001b[32m    821\u001b[39m \u001b[38;5;66;03m# Caches info about `call()` signature, args, kwargs.\u001b[39;00m\n\u001b[32m    822\u001b[39m call_spec = CallSpec(\u001b[38;5;28mself\u001b[39m._call_signature, args, kwargs)\n",
      "\u001b[31mValueError\u001b[39m: Only input tensors may be passed as positional arguments. The following argument value should be passed as a keyword argument: <Concatenate name=concatenate_9, built=False> (of type <class 'keras.src.layers.merging.concatenate.Concatenate'>)"
     ]
    }
   ],
   "source": [
    "high_res_ch_names = ['Fp1', 'Fz', 'F3', 'F7', 'FT9', 'FC5', 'FC1', 'C3', 'T7', 'TP9', 'CP5', 'CP1', 'Pz', 'P3', 'P7', 'O1', 'Oz', 'O2', 'P4', 'P8', 'TP10', 'CP6', 'CP2', 'C4', 'T8', 'FT10', 'FC6', 'FC2', 'F4', 'F8', 'Fp2', 'AF7', 'AF3', 'AFz', 'F1', 'F5', 'FT7', 'FC3', 'C1', 'C5', 'TP7', 'CP3', 'P1', 'P5', 'PO7', 'PO3', 'POz', 'PO4', 'PO8', 'P6', 'P2', 'CPz', 'CP4', 'TP8', 'C6', 'C2', 'FC4', 'FT8', 'F6', 'AF8', 'AF4', 'F2', 'FCz']\n",
    "low_res_ch_names = ['AF3', 'F7', 'F3', 'FC5', 'T7', 'P7', 'O1', 'O2', 'P8', 'T8', 'FC6', 'F4', 'F8', 'AF4']\n",
    "builtin_montage = 'standard_1020'\n",
    "time_steps = 57\n",
    "embed_dim = 14\n",
    "d_model = 60\n",
    "num_heads = 4\n",
    "mlp_dim = 128\n",
    "dropout_rate = 0.1\n",
    "\n",
    "input_epoch = Input(shape=(len(low_res_ch_names), time_steps)) # (batch_size, channels, time_steps)\n",
    "sim = SIM(embed_dim=embed_dim, d_model=d_model, num_heads=num_heads, mlp_dim=mlp_dim, dropout_rate=dropout_rate, low_res_ch_names=low_res_ch_names, high_res_ch_names=high_res_ch_names, builtin_montage=builtin_montage).generate(input_epoch, L=1, training=True)\n",
    "# trm = TRM(embed_dim=embed_dim, d_model=d_model, num_heads=num_heads, mlp_dim=mlp_dim, dropout_rate=dropout_rate)(sim, L=1, training=True)\n",
    "# model = sim + trm\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b757eedf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
