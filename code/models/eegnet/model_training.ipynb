{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af719db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import wandb\n",
    "import torch\n",
    "import GPUtil\n",
    "from EEGNet import EEGNet\n",
    "from torchinfo import summary\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "sys.path.append('../../')\n",
    "from utils.coco_data_handler import COCODataHandler\n",
    "from utils.epoch_data_reader import EpochDataReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf3e159a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\" # Force CUDA to use the GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  # Use first GPU\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\" # Enable memory optimization settings for PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34a8a94e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUtil found no available GPUs\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA is available\n",
    "try:\n",
    "    gpus = GPUtil.getGPUs()\n",
    "    if gpus:\n",
    "        print(f\"GPUtil detected {len(gpus)} GPUs:\")\n",
    "        for i, gpu in enumerate(gpus):\n",
    "            print(f\"  GPU {i}: {gpu.name} (Memory: {gpu.memoryTotal}MB)\")\n",
    "        \n",
    "        # Set default GPU\n",
    "        os.environ[\"CUDA_VISIBLE_DEVICES\"] = \",\".join([str(i) for i in range(len(gpus))])\n",
    "        print(f\"Set CUDA_VISIBLE_DEVICES={os.environ['CUDA_VISIBLE_DEVICES']}\")\n",
    "    else:\n",
    "        print(\"GPUtil found no available GPUs\")\n",
    "except Exception as e:\n",
    "    print(f\"Error checking GPUs with GPUtil: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46622f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Check for CUDA availability\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Print available GPU memory\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Total GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "    print(f\"Available GPU memory: {torch.cuda.memory_reserved(0) / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36081edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if torch.backends.mps.is_available():\n",
    "#     device = torch.device(\"mps\")\n",
    "# else:\n",
    "# Use CPU on Mac, there is a know bug with PyTorch\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ee17b2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accessory': 0,\n",
       " 'animal': 1,\n",
       " 'appliance': 2,\n",
       " 'electronic': 3,\n",
       " 'food': 4,\n",
       " 'furniture': 5,\n",
       " 'indoor': 6,\n",
       " 'kitchen': 7,\n",
       " 'outdoor': 8,\n",
       " 'person': 9,\n",
       " 'sports': 10,\n",
       " 'vehicle': 11}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coco_data = COCODataHandler.get_instance()\n",
    "coco_data.category_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e756ddd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = ['Fp1', 'AF7', 'AF3', 'F1', 'F3', 'F5', 'F7', 'FT7', 'FC5', 'FC3', 'FC1', 'C1', 'C3', 'C5', 'T7', 'TP7', 'CP5', 'CP3', 'CP1', 'P1', 'P3', 'P5', 'P7', 'P9', 'PO7', 'PO3', 'O1', 'Iz', 'Oz', 'POz', 'Pz', 'CPz', 'Fpz', 'Fp2', 'AF8', 'AF4', 'AFz', 'Fz', 'F2', 'F4', 'F6', 'F8', 'FT8', 'FC6', 'FC4', 'FC2', 'FCz', 'Cz', 'C2', 'C4', 'C6', 'T8', 'TP8', 'CP6', 'CP4', 'CP2', 'P2', 'P4', 'P6', 'P8', 'P10', 'PO8', 'PO4', 'O2']\n",
    "\n",
    "num_classes = len(coco_data.category_index.keys())\n",
    "model_type = \"low-resolution (downsampled)\" # \"super-resolution (upsampled)\" | \"high-resolution (ground-truth)\"\n",
    "\n",
    "# Training parameters\n",
    "epochs = 100\n",
    "\n",
    "# Optimizer parameters\n",
    "lr = 5e-5\n",
    "# weight_decay = 0.5\n",
    "# beta_1 = 0.9\n",
    "# beta_2 = 0.95\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "# Dataset parameters\n",
    "split = \"70/25/5\"\n",
    "epoch_type = \"around_evoked_event\"\n",
    "before = 0.05\n",
    "after = 0.6\n",
    "random_state = 97"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03af6730",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = EpochDataReader(\n",
    "    channel_names=channels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2298e4e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1437"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7151be7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_item = dataset[0][0]\n",
    "num_channels = sample_item.shape[0]\n",
    "time_steps = sample_item.shape[1]\n",
    "sfreq = dataset.resample_freq\n",
    "\n",
    "config = {\n",
    "    \"total_epochs_trained_on\": epochs,\n",
    "    \"model_type\": model_type,\n",
    "    \"time_steps_in_seconds\": time_steps / sfreq,\n",
    "    \"model_params\": {\n",
    "        \"model\": \"EEGNet\",\n",
    "        \"num_channels\": num_channels,\n",
    "        \"num_classes\": num_classes,\n",
    "        \"time_steps\": time_steps,\n",
    "        \"builtin_montage\": \"standard_1020\",\n",
    "    },\n",
    "    \"dataset_params\": {\n",
    "        \"subject_session_id\": dataset.subject_session_id,\n",
    "        \"epoch_type\": dataset.epoch_type,\n",
    "        \"split\": dataset.split,\n",
    "        \"duration\": str((dataset.before + dataset.after) * 1000) + 'ms' if dataset.epoch_type == 'around_evoked' else dataset.fixed_length_duration,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"random_state\": dataset.random_state\n",
    "    },\n",
    "    \"optimizer_params\": {\n",
    "        \"optimizer\": \"Adam\",\n",
    "        \"learning_rate\": lr,\n",
    "        # \"weight_decay\": weight_decay,\n",
    "        # \"betas\": (beta_1, beta_2)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50c036cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "EEGNet                                   --\n",
       "├─Ensure4d: 1-1                          --\n",
       "├─Expression: 1-2                        --\n",
       "├─Conv2d: 1-3                            512\n",
       "├─BatchNorm2d: 1-4                       16\n",
       "├─Conv2dWithConstraint: 1-5              1,024\n",
       "├─BatchNorm2d: 1-6                       32\n",
       "├─Expression: 1-7                        --\n",
       "├─AvgPool2d: 1-8                         --\n",
       "├─Dropout: 1-9                           --\n",
       "├─Conv2d: 1-10                           256\n",
       "├─Conv2d: 1-11                           256\n",
       "├─BatchNorm2d: 1-12                      32\n",
       "├─Expression: 1-13                       --\n",
       "├─AvgPool2d: 1-14                        --\n",
       "├─Dropout: 1-15                          --\n",
       "├─Flatten: 1-16                          --\n",
       "├─Linear: 1-17                           82,432\n",
       "├─Linear: 1-18                           6,156\n",
       "=================================================================\n",
       "Total params: 90,716\n",
       "Trainable params: 90,716\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = EEGNet(device, num_channels, time_steps, num_classes)\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d7f1df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdubs2310\u001b[0m (\u001b[33mdubs2310-cal-poly-pomona\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/asifrasheed/eeg-image-decoding/code/models/eegnet/wandb/run-20250514_045713-e4h4u1za</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dubs2310-cal-poly-pomona/eeg-eegnet/runs/e4h4u1za' target=\"_blank\">wobbly-feather-48</a></strong> to <a href='https://wandb.ai/dubs2310-cal-poly-pomona/eeg-eegnet' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dubs2310-cal-poly-pomona/eeg-eegnet' target=\"_blank\">https://wandb.ai/dubs2310-cal-poly-pomona/eeg-eegnet</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dubs2310-cal-poly-pomona/eeg-eegnet/runs/e4h4u1za' target=\"_blank\">https://wandb.ai/dubs2310-cal-poly-pomona/eeg-eegnet/runs/e4h4u1za</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint from cpoints/eegnet_classification_best.pt\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">wobbly-feather-48</strong> at: <a href='https://wandb.ai/dubs2310-cal-poly-pomona/eeg-eegnet/runs/e4h4u1za' target=\"_blank\">https://wandb.ai/dubs2310-cal-poly-pomona/eeg-eegnet/runs/e4h4u1za</a><br> View project at: <a href='https://wandb.ai/dubs2310-cal-poly-pomona/eeg-eegnet' target=\"_blank\">https://wandb.ai/dubs2310-cal-poly-pomona/eeg-eegnet</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250514_045713-e4h4u1za/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(\n",
    "    params=[{'params': model.parameters()}], \n",
    "    lr=lr\n",
    ")\n",
    "\n",
    "with wandb.init(project=\"eeg-eegnet\", config=config) as run:\n",
    "    history = model.fit(loader, 1, optimizer, 'cpoints', 'classification', use_checkpoint=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492b2341",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "loader.dataset.set_split_type('all')\n",
    "\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "\n",
    "for batch in loader:\n",
    "    epochs = batch[0]\n",
    "    one_hot_encoding = batch[1]\n",
    "    y_pred = model.predict(epochs)\n",
    "\n",
    "    all_preds.append(y_pred)\n",
    "    all_targets.append(one_hot_encoding)\n",
    "\n",
    "all_preds = np.concatenate(all_preds, axis=0)  \n",
    "all_targets = np.concatenate(all_targets, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2412caed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   accessory       0.00      0.00      0.00      5599\n",
      "      animal       0.00      0.00      0.00     10825\n",
      "   appliance       0.00      0.00      0.00      3160\n",
      "  electronic       0.00      0.00      0.00      3878\n",
      "        food       0.00      0.00      0.00      6086\n",
      "   furniture       0.00      0.00      0.00      9770\n",
      "      indoor       0.00      0.00      0.00      5651\n",
      "     kitchen       0.00      0.00      0.00      6558\n",
      "     outdoor       0.00      0.00      0.00      4358\n",
      "      person       0.51      0.84      0.64     23413\n",
      "      sports       0.00      0.00      0.00      9479\n",
      "     vehicle       0.00      0.00      0.00     10721\n",
      "\n",
      "   micro avg       0.51      0.20      0.29     99498\n",
      "   macro avg       0.04      0.07      0.05     99498\n",
      "weighted avg       0.12      0.20      0.15     99498\n",
      " samples avg       0.43      0.18      0.25     99498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels = list(coco_data.category_index.keys())\n",
    "print(classification_report(all_targets, all_preds, target_names=labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
