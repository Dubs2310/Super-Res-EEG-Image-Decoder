{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afce74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import wandb\n",
    "import GPUtil\n",
    "import torch.optim as optim\n",
    "from models.estformer.ESTFormer import ESTFormer\n",
    "from torchinfo import summary\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "sys.path.append('../../')\n",
    "from utils.hdf5_data_split_generator import HDF5DataSplitGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98a50522",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\" # Force CUDA to use the GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  # Use first GPU\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\" # Enable memory optimization settings for PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "085b474e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUtil detected 1 GPUs:\n",
      "  GPU 0: NVIDIA GeForce RTX 3070 Laptop GPU (Memory: 8192.0MB)\n",
      "Set CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA is available\n",
    "try:\n",
    "    gpus = GPUtil.getGPUs()\n",
    "    if gpus:\n",
    "        print(f\"GPUtil detected {len(gpus)} GPUs:\")\n",
    "        for i, gpu in enumerate(gpus):\n",
    "            print(f\"  GPU {i}: {gpu.name} (Memory: {gpu.memoryTotal}MB)\")\n",
    "        \n",
    "        # Set default GPU\n",
    "        os.environ[\"CUDA_VISIBLE_DEVICES\"] = \",\".join([str(i) for i in range(len(gpus))])\n",
    "        print(f\"Set CUDA_VISIBLE_DEVICES={os.environ['CUDA_VISIBLE_DEVICES']}\")\n",
    "    else:\n",
    "        print(\"GPUtil found no available GPUs\")\n",
    "except Exception as e:\n",
    "    print(f\"Error checking GPUs with GPUtil: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5fd6d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Total GPU memory: 8.59 GB\n",
      "Available GPU memory: 0.00 GB\n"
     ]
    }
   ],
   "source": [
    "# Check for CUDA availability\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Print available GPU memory\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Total GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "    print(f\"Available GPU memory: {torch.cuda.memory_reserved(0) / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7eb17a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_channels = ['Fp1', 'AF7', 'AF3', 'F1', 'F3', 'F5', 'F7', 'FT7', 'FC5', 'FC3', 'FC1', 'C1', 'C3', 'C5', 'T7', 'TP7', 'CP5', 'CP3', 'CP1', 'P1', 'P3', 'P5', 'P7', 'P9', 'PO7', 'PO3', 'O1', 'Iz', 'Oz', 'POz', 'Pz', 'CPz', 'Fpz', 'Fp2', 'AF8', 'AF4', 'AFz', 'Fz', 'F2', 'F4', 'F6', 'F8', 'FT8', 'FC6', 'FC4', 'FC2', 'FCz', 'Cz', 'C2', 'C4', 'C6', 'T8', 'TP8', 'CP6', 'CP4', 'CP2', 'P2', 'P4', 'P6', 'P8', 'P10', 'PO8', 'PO4', 'O2']\n",
    "\n",
    "# Model parameters\n",
    "hr_channel_names = all_channels # High-resolution setup (all channels)\n",
    "lr_channel_names = ['AF3', 'F7', 'F3', 'FC5', 'T7', 'P7', 'O1', 'O2', 'P8', 'T8', 'FC6', 'F4', 'F8', 'AF4'] # Low-resolution setup (fewer channels)\n",
    "builtin_montage = 'standard_1020'\n",
    "alpha_t = 0.60\n",
    "alpha_s = 0.75\n",
    "r_mlp = 4 # amplification factor for MLP layers\n",
    "dropout_rate = 0.5\n",
    "L_s = 1  # Number of spatial layers\n",
    "L_t = 1  # Number of temporal layers\n",
    "\n",
    "# Training parameters\n",
    "epochs = 30\n",
    "\n",
    "# Optimizer parameters\n",
    "lr = 5e-5\n",
    "weight_decay = 0.5\n",
    "beta_1 = 0.9\n",
    "beta_2 = 0.95\n",
    "\n",
    "# Dataset parameters\n",
    "batch_size = 30\n",
    "dataset_split = \"70/25/5\"\n",
    "eeg_epoch_mode = \"fixed_length\"\n",
    "fixed_length_duration = 6\n",
    "duration_before_onset = 0.05\n",
    "duration_after_onset = 0.6\n",
    "random_state = 97"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79149aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets\n",
    "train_dataset = HDF5DataSplitGenerator(\n",
    "    dataset_type=\"train\",\n",
    "    dataset_split=dataset_split,\n",
    "    eeg_epoch_mode=eeg_epoch_mode,\n",
    "    random_state=random_state,\n",
    "    fixed_length_duration=fixed_length_duration,\n",
    "    duration_before_onset=duration_before_onset,\n",
    "    duration_after_onset=duration_after_onset,\n",
    "    lr_channel_names=lr_channel_names,\n",
    "    hr_channel_names=hr_channel_names\n",
    ")\n",
    "\n",
    "val_dataset = HDF5DataSplitGenerator(\n",
    "    dataset_type=\"val\",\n",
    "    dataset_split=dataset_split,\n",
    "    eeg_epoch_mode=eeg_epoch_mode,\n",
    "    random_state=random_state,\n",
    "    fixed_length_duration=fixed_length_duration,\n",
    "    duration_before_onset=duration_before_onset,\n",
    "    duration_after_onset=duration_after_onset,\n",
    "    lr_channel_names=lr_channel_names,\n",
    "    hr_channel_names=hr_channel_names\n",
    ")\n",
    "\n",
    "test_dataset = HDF5DataSplitGenerator(\n",
    "    dataset_type=\"test\",\n",
    "    dataset_split=dataset_split,\n",
    "    eeg_epoch_mode=eeg_epoch_mode,\n",
    "    random_state=random_state,\n",
    "    fixed_length_duration=fixed_length_duration,\n",
    "    duration_before_onset=duration_before_onset,\n",
    "    duration_after_onset=duration_after_onset,\n",
    "    lr_channel_names=lr_channel_names,\n",
    "    hr_channel_names=hr_channel_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59be6a5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(162, 58, 12)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "len(train_loader), len(val_loader), len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6956e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdubs2310\u001b[0m (\u001b[33mdubs2310-cal-poly-pomona\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>s:\\PolySecLabProjects\\eeg-image-decode\\code\\models\\estformer\\wandb\\run-20250511_023912-w2xkm794</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dubs2310-cal-poly-pomona/eeg-estformer/runs/w2xkm794' target=\"_blank\">twilight-dew-47</a></strong> to <a href='https://wandb.ai/dubs2310-cal-poly-pomona/eeg-estformer' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dubs2310-cal-poly-pomona/eeg-estformer' target=\"_blank\">https://wandb.ai/dubs2310-cal-poly-pomona/eeg-estformer</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dubs2310-cal-poly-pomona/eeg-estformer/runs/w2xkm794' target=\"_blank\">https://wandb.ai/dubs2310-cal-poly-pomona/eeg-estformer/runs/w2xkm794</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/dubs2310-cal-poly-pomona/eeg-estformer/runs/w2xkm794?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x1e446122550>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get sample data to determine time_steps\n",
    "sample_item = train_loader.dataset[0]\n",
    "time_steps = sample_item[\"lo_res\"].shape[1]\n",
    "sfreq = sample_item[\"sfreq\"]\n",
    "\n",
    "config = {\n",
    "    \"total_epochs_trained_on\": epochs,\n",
    "    \"subject\": \"all\",\n",
    "    \"scale_factor\": len(hr_channel_names) / len(lr_channel_names),\n",
    "    \"time_steps_in_seconds\": time_steps / sfreq,\n",
    "    \"is_parieto_occipital_exclusive\": all(ch.startswith(('P', 'O')) for ch in lr_channel_names) and all(ch.startswith(('P', 'O')) for ch in hr_channel_names),\n",
    "    \"model_params\": {\n",
    "        \"model\": \"ESTformer\",\n",
    "        \"num_lr_channels\": len(lr_channel_names),\n",
    "        \"num_hr_channels\": len(hr_channel_names),\n",
    "        \"builtin_montage\": builtin_montage,\n",
    "        \"alpha_s\": alpha_s,\n",
    "        \"alpha_t\": alpha_t,\n",
    "        \"r_mlp\": r_mlp,\n",
    "        \"dropout_rate\": dropout_rate,\n",
    "        \"L_s\": L_s,\n",
    "        \"L_t\": L_t,\n",
    "    },\n",
    "    \"dataset_params\": {\n",
    "        \"eeg_epoch_mode\": eeg_epoch_mode,\n",
    "        \"dataset_split\": dataset_split,\n",
    "        \"fixed_length_duration\": fixed_length_duration,\n",
    "        \"duration_before_onset\": duration_before_onset,\n",
    "        \"duration_after_onset\": duration_after_onset,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"random_state\": random_state\n",
    "    },\n",
    "    \"optimizer_params\": {\n",
    "        \"optimizer\": \"Adam\",\n",
    "        \"learning_rate\": lr,\n",
    "        \"weight_decay\": weight_decay,\n",
    "        \"betas\": (beta_1, beta_2)\n",
    "    }\n",
    "}\n",
    "\n",
    "wandb.init(project=\"eeg-estformer\", config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2a24fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "s:\\PolySecLabProjects\\eeg-image-decode\\env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1341: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\c10/cuda/CUDAAllocatorConfig.h:28.)\n",
      "  return t.to(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==============================================================================================================\n",
       "Layer (type:depth-idx)                                                                Param #\n",
       "==============================================================================================================\n",
       "ESTFormer                                                                             1,845\n",
       "├─SigmaParameters: 1-1                                                                2\n",
       "├─SIM: 1-2                                                                            --\n",
       "│    └─Linear: 2-1                                                                    5,669,685\n",
       "│    └─LayerNorm: 2-2                                                                 3,690\n",
       "│    └─CAB: 2-3                                                                       --\n",
       "│    │    └─ModuleList: 3-1                                                           40,877,353\n",
       "│    └─MaskTokensInsert: 2-4                                                          --\n",
       "│    │    └─MaskTokenExpander: 3-2                                                    1,845\n",
       "│    └─Linear: 2-5                                                                    3,405,870\n",
       "│    └─CAB: 2-6                                                                       --\n",
       "│    │    └─ModuleList: 3-3                                                           40,972,253\n",
       "│    └─LayerNorm: 2-7                                                                 3,690\n",
       "│    └─Linear: 2-8                                                                    5,670,912\n",
       "├─TRM: 1-3                                                                            --\n",
       "│    └─Linear: 2-9                                                                    3,120\n",
       "│    └─SAB: 2-10                                                                      --\n",
       "│    │    └─ModuleList: 3-4                                                           28,272\n",
       "│    └─LayerNorm: 2-11                                                                6,144\n",
       "│    └─Linear: 2-12                                                                   2,352\n",
       "│    └─SAB: 2-13                                                                      --\n",
       "│    │    └─ModuleList: 3-5                                                           28,272\n",
       "│    └─LayerNorm: 2-14                                                                6,144\n",
       "│    └─Linear: 2-15                                                                   3,136\n",
       "├─LayerNorm: 1-4                                                                      393,216\n",
       "==============================================================================================================\n",
       "Total params: 97,077,801\n",
       "Trainable params: 97,077,801\n",
       "Non-trainable params: 0\n",
       "=============================================================================================================="
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ESTFormer(\n",
    "    device=device, \n",
    "    lr_channel_names=lr_channel_names,\n",
    "    hr_channel_names=hr_channel_names,\n",
    "    builtin_montage=builtin_montage,\n",
    "    time_steps=time_steps,\n",
    "    alpha_t=alpha_t,\n",
    "    alpha_s=alpha_s,\n",
    "    r_mlp=r_mlp,\n",
    "    dropout_rate=dropout_rate,\n",
    "    L_s=L_s,\n",
    "    L_t=L_t\n",
    ")\n",
    "\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d23025e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/30:   0%|          | 0/162 [00:28<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Create optimizer with both model and sigma parameters\u001b[39;00m\n\u001b[32m      2\u001b[39m optimizer = optim.Adam(\n\u001b[32m      3\u001b[39m     params=[{\u001b[33m'\u001b[39m\u001b[33mparams\u001b[39m\u001b[33m'\u001b[39m: model.parameters()}], \n\u001b[32m      4\u001b[39m     lr=lr,\n\u001b[32m      5\u001b[39m     weight_decay=weight_decay,\n\u001b[32m      6\u001b[39m     betas=(beta_1, beta_2)\n\u001b[32m      7\u001b[39m )\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m history = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheckpoint_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcheckpoints\u001b[39;49m\u001b[33;43m'\u001b[39;49m\n\u001b[32m     15\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32ms:\\PolySecLabProjects\\eeg-image-decode\\code\\models\\estformer\\model.py:515\u001b[39m, in \u001b[36mESTFormer.fit\u001b[39m\u001b[34m(self, epochs, train_loader, val_loader, optimizer, checkpoint_dir)\u001b[39m\n\u001b[32m    512\u001b[39m \u001b[38;5;28mself\u001b[39m.best_val_loss = \u001b[38;5;28mfloat\u001b[39m(\u001b[33m'\u001b[39m\u001b[33minf\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    514\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[32m--> \u001b[39m\u001b[32m515\u001b[39m     train_metrics = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining_pass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    516\u001b[39m     val_metrics = \u001b[38;5;28mself\u001b[39m.validation_pass()\n\u001b[32m    518\u001b[39m     log_object = { \u001b[33m\"\u001b[39m\u001b[33mepoch\u001b[39m\u001b[33m\"\u001b[39m: epoch + \u001b[32m1\u001b[39m }\n",
      "\u001b[36mFile \u001b[39m\u001b[32ms:\\PolySecLabProjects\\eeg-image-decode\\code\\models\\estformer\\model.py:409\u001b[39m, in \u001b[36mESTFormer.training_pass\u001b[39m\u001b[34m(self, epoch)\u001b[39m\n\u001b[32m    406\u001b[39m outputs = \u001b[38;5;28mself\u001b[39m(lo_res)\n\u001b[32m    408\u001b[39m \u001b[38;5;66;03m# Compute loss\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m409\u001b[39m loss = \u001b[43mreconstruction_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhi_res\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msigmas\u001b[49m\u001b[43m.\u001b[49m\u001b[43msigma1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msigmas\u001b[49m\u001b[43m.\u001b[49m\u001b[43msigma2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    410\u001b[39m mae = compute_mean_absolute_error(hi_res, outputs)\n\u001b[32m    411\u001b[39m nmse = compute_normalized_mean_squared_error(hi_res, outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32ms:\\PolySecLabProjects\\eeg-image-decode\\code\\models\\estformer\\..\\..\\utils\\metrics.py:36\u001b[39m, in \u001b[36mloss\u001b[39m\u001b[34m(y_true, y_pred, sigma1, sigma2)\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     25\u001b[39m \u001b[33;03mCustom loss function combining frequency domain MSE and time domain MAE\u001b[39;00m\n\u001b[32m     26\u001b[39m \u001b[33;03m\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     33\u001b[39m \u001b[33;03m    Scalar loss value.\u001b[39;00m\n\u001b[32m     34\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     35\u001b[39m \u001b[38;5;66;03m# Convert to complex tensors for FFT\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m fft_true = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfft\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrfft\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     37\u001b[39m fft_pred = torch.fft.rfft(y_pred.to(torch.float32))\n\u001b[32m     38\u001b[39m fmse = torch.mean(torch.abs(fft_true - fft_pred) ** \u001b[32m2\u001b[39m) \u001b[38;5;66;03m# Compute frequency domain MSE\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Create optimizer with both model and sigma parameters\n",
    "optimizer = optim.Adam(\n",
    "    params=[{'params': model.parameters()}], \n",
    "    lr=lr,\n",
    "    weight_decay=weight_decay,\n",
    "    betas=(beta_1, beta_2)\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    epochs=epochs,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    optimizer=optimizer,\n",
    "    checkpoint_dir='checkpoints'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f3f100",
   "metadata": {},
   "outputs": [],
   "source": [
    "monitor_sigma_values_and_loss(history)\n",
    "visualize_results(model, val_loader.dataset, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56446abd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
